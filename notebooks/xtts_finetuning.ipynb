{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th91ofnQWr8Y"
      },
      "source": [
        "# Preparación de Dataset, finetuning del modelo e inferencias con XTTS\n",
        "\n",
        "## Setear el entorno\n",
        "Para empezar el demo se debe **instalar** el reposotorio de **Coqui** y sus **dependencias** (ignorar los errores de pip install).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n793CEv0_Xi5"
      },
      "source": [
        "Antes de ejecutar asegurarse que en el entorno de ejecución se encuentra seleccionada la opción de \"**acelerador por hardware**\": **T4 GPU**\n",
        "- Dirigirse a la pestaña \"Entorno de Ejecución\"\n",
        "- Cambiar tipo de entorno de ejecución\n",
        "- Seleccionar *tipo de entorno:* **Python3** y *acelerador por hardware:* **T4 GPU**\n",
        "- Click en guardar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_k-_a0KAOpG"
      },
      "source": [
        "Luego vamos a configurar el colab para que no se cuelgue por **inactividad**:\n",
        "\n",
        "* Habilitar las *Dev Tools* del *browser*: `CTRL + SHIFT + I`.\n",
        "* Ingresar a *console*.\n",
        "* Ingresar a mano (no copiando y pegando) en la consola: `allow pasting`.\n",
        "* Copiar y pegar la función de acontinuacion (ahora si se encuentra habilitado).\n",
        "* Presionar ENTER para correr la función.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdYsZFBPARsa"
      },
      "source": [
        "\n",
        "\n",
        "``` javascript\n",
        "function ClickConnect() {\n",
        "  var iconElement = document.getElementById(\"toggle-header-button\");\n",
        "  if (iconElement) {\n",
        "    var clickEvent = new MouseEvent (\"click\", {\n",
        "    bubbles: true, cancelable: true,\n",
        "    view: window\n",
        "    });\n",
        "    iconElement.dispatchEvent (clickEvent);\n",
        "  }\n",
        "}\n",
        "setInterval(ClickConnect, 6000);\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzYT_S5IzLaW"
      },
      "source": [
        "Por ultimo vamos agregar las variables de entorno en el notebook del colab, siguiendo los siguientes [pasos](https://www.notion.so/Voice-cloning-XTTS-d87ef69100894a2d983e65e70c02ab4c?pvs=4#3cf61e06d7044f59912e88bd5fdc711a)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lmUUQqdN6BXk",
        "outputId": "d8e45cfb-7391-46d3-f996-c66bb325cc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "chex 0.1.85 requires numpy>=1.24.1, but you'll have numpy 1.22.0 which is incompatible.\n",
            "librosa 0.10.1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you'll have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you'll have numpy 1.22.0 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you'll have networkx 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you'll have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tts 0.20.6 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.2 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you have networkx 3.2.1 which is incompatible.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title ### Instalar requirimientos\n",
        "!rm -rf sintetica-service-xtts/ # delete repo to be able to reinstall if needed\n",
        "!git clone --branch main -q  https://github.com/mecantronic/sintetica-service-xtts.git\n",
        "!pip install --use-deprecated=legacy-resolver -q -e TTS\n",
        "!pip install --use-deprecated=legacy-resolver -q -r TTS/TTS/demos/xtts_ft_demo/requirements.txt\n",
        "!pip install -q typing_extensions==4.8 numpy==1.26.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4pWQxBShEGF"
      },
      "source": [
        "## Requisitos para los datos:\n",
        "\n",
        "- La duración total de los audios debe estar aproximadamente entre **5-6 minutos**\n",
        "- **Formato**: Preferiblemente **WAV 22050 Hz de frecuencia de muestreo y 16 bits de resolución**. Formatos compatibles: wav, mp3 y flac.\n",
        "  - Puede pasarse también audios en **44100 Hz de frecuencia de muestreo**\n",
        "- Se pueden pasar varios audios de menor duración o se puede pasar un único audio con la duración requerida\n",
        "  - En caso de pasar un único audio, es vital prestar atención a que no haya silencios de larga duración entre las partes habladas.\n",
        "- Evitar que los audios contengan muchas pausas y/o balbuceos. Cuánto mas fluidas y concretas las oraciones que se enuncian mejor.\n",
        "- Debe contener la menor cantidad de ruido de fondo posible.\n",
        "- Si hay más de un hablante, recortar las partes del hablante de interés. Si en alguna parte del diálogo el hablante es pisado por otra persona, descartar esa parte\n",
        "- Si se recortan los audios de forma manual, evitar recortar oraciones o frases por la mitad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExQkwF1eqSDa",
        "outputId": "fb446b6b-b319-41fd-d8d1-cd2607a75712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://0.0.0.0:5003\n",
            "Running on public URL: https://05f1472c61c4dbf7d5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Loading Whisper Model!\n",
            "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]\n",
            "tokenizer.json: 100%|##########| 2.20M/2.20M [00:00<00:00, 30.8MB/s]\n",
            "config.json: 100%|##########| 2.80k/2.80k [00:00<00:00, 8.89MB/s]\n",
            "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]\n",
            "vocabulary.txt: 100%|##########| 460k/460k [00:00<00:00, 4.42MB/s]\n",
            "model.bin: 100%|##########| 3.09G/3.09G [00:34<00:00, 90.7MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sintetica-service-xtts/xtts_finetuning.py\", line 215, in preprocess_dataset\n",
            "    train_meta, eval_meta, audio_total_size = format_audio_list(audio_path, target_language=language, out_path=out_path, gradio_progress=progress)\n",
            "  File \"/content/sintetica-service-xtts/utils/formatter.py\", line 56, in format_audio_list\n",
            "    asr_model = WhisperModel(\"large-v2\", device=device, compute_type=\"float16\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/faster_whisper/transcribe.py\", line 128, in __init__\n",
            "    self.model = ctranslate2.models.Whisper(\n",
            "ValueError: Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2194, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sintetica-service-xtts/xtts_finetuning.py\", line 410, in <module>\n",
            "    demo.launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2101, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2198, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 75, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:5003 <> https://05f1472c61c4dbf7d5.gradio.live\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title Iniciar la interfaz de Gradio\n",
        "# @markdown Ejecutar celda y, luego, clickear en el enlace `Running on public URL: ` cuando el demo esté listo\n",
        "\n",
        "!python TTS/TTS/demos/xtts_ft_demo/xtts_finetunning.py --batch_size 2 --num_epochs 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSlFcnywPcnG"
      },
      "source": [
        "## Configurar conexión con AWS\n",
        "\n",
        "Ejecutar las siguientes 3 celdas para instalar **AWS CLI**, conectarse al almacenamiento y poder guardar los pesos del modelo entrenado en el **Bucket S3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtAK2HIWPgTS",
        "outputId": "de7a1a2c-4689-4281-d3fb-4b36519ee96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.32.44-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.34.44 (from awscli)\n",
            "  Downloading botocore-1.34.44-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.11.0,>=0.10.0 (from awscli)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
            "Collecting colorama<0.4.5,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.34.44->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.44->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.44->awscli) (2.0.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.44->awscli) (1.16.0)\n",
            "Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.32.44 botocore-1.34.44 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.10.0\n"
          ]
        }
      ],
      "source": [
        "# @title ### Instalar AWS CLI\n",
        "!pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuRxJ7a8FQkn"
      },
      "outputs": [],
      "source": [
        "# @title Configuración AWS\n",
        "from google.colab import userdata\n",
        "\n",
        "AWS_ACCESS_KEY_ID = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
        "AWS_DEFAULT_REGION = userdata.get(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7eKHuySFV_4"
      },
      "outputs": [],
      "source": [
        "# @title Configuración Bucket\n",
        "!aws configure set default.aws_access_key_id $AWS_ACCESS_KEY_ID\n",
        "!aws configure set default.aws_secret_access_key $AWS_SECRET_ACCESS_KEY\n",
        "!aws configure set default.region $AWS_DEFAULT_REGION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpfdzHvKaX8M"
      },
      "outputs": [],
      "source": [
        "# @title ## Descarga del mejor modelo y resultados\n",
        "# @markdown **Ejecutar celda para localizar el mejor modelo y preparar para subirlo**\n",
        "from google.colab import files\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "\n",
        "def find_latest_best_model(folder_path):\n",
        "    search_path = os.path.join(folder_path, '**', 'best_model.pth')\n",
        "    files = glob.glob(search_path, recursive=True)\n",
        "    latest_file = max(files, key=os.path.getctime, default=None)\n",
        "    return latest_file\n",
        "\n",
        "model_path = find_latest_best_model(\"/tmp/xtts_ft/run/training/\")\n",
        "checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
        "del checkpoint[\"optimizer\"]\n",
        "for key in list(checkpoint[\"model\"].keys()):\n",
        "    if \"dvae\" in key:\n",
        "        del checkpoint[\"model\"][key]\n",
        "torch.save(checkpoint, \"model.pth\")\n",
        "model_dir = os.path.dirname(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZsvfIUb8Jga"
      },
      "outputs": [],
      "source": [
        "# @title Ingresar nombre de hablante y luego ejecutar celda\n",
        "# @markdown **Con el siguiente formato: \"apellido_nombre\"**\n",
        "speaker_name = '' #@param {type:\"string\"}\n",
        "\n",
        "# Copy files into folder to upload to Bucket\n",
        "upload_path = \"./model_outputs/\"\n",
        "os.mkdir(upload_path)\n",
        "\n",
        "shutil.copy(os.path.join(model_dir, 'config.json'), os.path.join(upload_path, 'config.json'))\n",
        "shutil.copy(os.path.join(model_dir, 'vocab.json'), os.path.join(upload_path, 'vocab.json'))\n",
        "shutil.copy('model.pth', os.path.join(upload_path, \"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJC1FLMy88Ne",
        "outputId": "63e41bee-f482-4e36-f932-bd6c9946e2fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "upload: model_outputs/config.json to s3://mecantronic-voice-cloning/weights/end-to-end/xtts_delmoro/config.json\n",
            "upload: model_outputs/vocab.json to s3://mecantronic-voice-cloning/weights/end-to-end/xtts_delmoro/vocab.json\n",
            "upload: model_outputs/model.pth to s3://mecantronic-voice-cloning/weights/end-to-end/xtts_delmoro/model.pth\n"
          ]
        }
      ],
      "source": [
        "# @title ## Subir archivos del modelo entrenado al Bucket S3\n",
        "!aws s3 cp $upload_path s3://mecantronic-voice-cloning/weights/end-to-end/xtts_$speaker_name/ --recursive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
